\documentclass{article}

\usepackage{graphicx}
\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{url}
\usepackage[usenames]{color}

\newcommand{\figref}[1]{Figure~\ref{#1}}

\pagestyle{empty} \addtolength{\textwidth}{1.0in}
\addtolength{\textheight}{0.5in} \addtolength{\oddsidemargin}{-0.5in}
\addtolength{\evensidemargin}{-0.5in}
\newcommand{\ruleskip}{\bigskip\hrule\bigskip}
\newcommand{\nodify}[1]{{\sc #1}} \newcommand{\points}[1]{{\textbf{[#1
points]}}}

\newcommand{\bitem}{\begin{list}{$\bullet$}%
{\setlength{\itemsep}{0pt}\setlength{\topsep}{0pt}%
\setlength{\rightmargin}{0pt}}} \newcommand{\eitem}{\end{list}}

\newcommand{\G}{\mathcal{G}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}

%\newcommand{\bE}{\mbox{\boldmath $E$}}
%\newcommand{\be}{\mbox{\boldmath $e$}}
%\newcommand{\bU}{\mbox{\boldmath $U$}}
%\newcommand{\bu}{\mbox{\boldmath $u$}}
%\newcommand{\bQ}{\mbox{\boldmath $Q$}}
%\newcommand{\bq}{\mbox{\boldmath $q$}}
%\newcommand{\bX}{\mbox{\boldmath $X$}}
%\newcommand{\bY}{\mbox{\boldmath $Y$}}
%\newcommand{\bZ}{\mbox{\boldmath $Z$}}
%\newcommand{\bx}{\mbox{\boldmath $x$}}
%\newcommand{\by}{\mbox{\boldmath $y$}}
%\newcommand{\bz}{\mbox{\boldmath $z$}}

\newcommand{\true}{\mbox{true}}
\newcommand{\Parents}{\mbox{Parents}}

\newcommand{\ww}{{\bf w}}
\newcommand{\xx}{{\bf x}}
\newcommand{\yy}{{\bf y}}
\newcommand{\real}{\ensuremath{\mathbb{R}}}


\newcommand{\eat}[1]{}

\newcommand{\CInd}[3]{({#1} \perp {#2} \mid {#3})}
\newcommand{\Ind}[2]{({#1} \perp {#2})}

\setlength{\parindent}{0pt} \setlength{\parskip}{0.5ex}

\begin{document}

\pagestyle{myheadings} \markboth{}{DS-GA-1005/CSCI-GA.2569 Problem Set 5}

{\LARGE
\begin{center}Inference and Representation, Fall 2016\end{center}
}

{\Large
Problem Set 5: PCA \& Factor Analysis
}


{\bf Due: Monday, October 24, 2016 at 3pm (as a PDF document uploaded in
  Gradescope.)}\\

{\em {\bf Important:} See problem set policy on the course web site.}
\ruleskip

%\vspace{0.2in}

\begin{enumerate}

\item \emph{Non-negative Matrix Factorization (NMF)} [Lee and Seung'99] is an alternative to PCA when 
data and factors can be cast as non-negative. We seek to factorize the $N \times p$ data matrix $\mathbf{X}$ as
\begin{equation}
\mathbf{X} \approx \mathbf{ W ~H}~,
\end{equation}
where $\mathbf{W}$ is $N \times r$ and $\mathbf{H}$ is $r \times p$, with $r \leq \max(N,p)$, and 
we assume that $x_{ij}, w_{ik}, h_{kj} \geq 0$.
\begin{enumerate}
\item Suppose that $x_{ij} \in \mathbb{N}$. If we model each random variable $x_{ij}$ as a Poisson 
random variable with mean $(WH)_{ij}$, show that the log-likelihood of the model is (up to a constant) 
\begin{equation}
\label{bla}
\mathcal{L}(\mathbf{W}, \mathbf{H}) = \sum_{i, j} [x_{ij} \log( (WH)_{ij} ) - (WH)_{ij}] ~.
\end{equation}

\end{enumerate}

 The following alternating algorithm (Lee, Seung, '01) converges to a local maximum of $\mathcal{L}(\mathbf{W}, \mathbf{H})$:
\begin{eqnarray}
\label{ble}
w_{ik} &\leftarrow& w_{ik} \frac{\sum_j h_{kj}x_{ij} / ( WH)_{ij}}{\sum_j h_{kj}}~,\\
h_{kj} &\leftarrow& h_{kj} \frac{\sum_i w_{ik}x_{ij} / ( WH)_{ij}}{\sum_j w_{kj}}~,.
\end{eqnarray}
We shall study this algorithm and prove its correctness. 

A function $g(x,y)$ is said to minorize a function $f(x)$ if 
$$\forall~(x,y)~,~g(x,y) \leq f(x)~,~g(x,x) = f(x)~.$$
\begin{enumerate}
\setcounter{enumi}{1}
\item Show that under the update 
$$x^{t+1} = \arg\max_x g(x,x^t)$$
the sequence $f_t = f(x^t)$ is non-decreasing. 
\item Using concavity of the logarithm, show that for any set of $r$ values $y_k \geq 0$ 
and $0 \leq c_k \leq 1$ with $\sum_{k \leq r} c_k = 1$, 
$$\log \left( \sum_{k \leq r} y_k \right) \geq \sum_{k \leq r} c_k \log( y_k / c_k)~.$$
\item Deduce that 
$$\log \left( \sum_{k \leq r} w_{ik} h_{kj} \right) \geq \sum_{k \leq r} c_{kij} \log( w_{ik} h_{kj} / c_{kij})~,$$
where $c_{kij} = \frac{w_{ik}^t h_{kj}^t}{ \sum_{k' \leq r} w_{ik'}^t h_{k'j}^t} $ and $t$ is the current iteration.
\item Ignoring constants, show that 
$$g(\mathbf{W}, \mathbf{H}; \mathbf{W}^t, \mathbf{H}^t) = \sum_{i,j,k} [x_{ij} c_{kij} (\log w_{ik} + \log h_{kj}) - w_{ik}h_{kj} ]$$
minorizes $\mathcal{L}(\mathbf{W}, \mathbf{H})$. 
\item Finally, derive the update steps (\ref{ble}) by setting to zero the partial derivatives of $g$.
\end{enumerate}

\item \emph{Factor Analysis, Covariance and Correlation}. 
Recall that the covariance and correlation of two random variables $X_i$, $X_j$ defined respectively as 
$$\sigma_{i,j} = \E( (X_i - \E X_i)(X_j - \E X_j))~,~\tilde{\sigma}_{i,j} = \frac{\sigma_{i,j}}{\sqrt{\sigma_{i,i} \sigma_{j,j}}}~.$$
\begin{enumerate}
\item Show that $-1 \leq \tilde{\sigma}_{ij} \leq 1$.
\item Show how Factor Analysis applied to the covariance matrix $\Sigma$ of $X$ and the corresponding Factor Analysis applied to the correlation matrix $\tilde{\Sigma}$ of $X$ are related. Interpret this result. Does the same phenomena hold 
if you apply PCA to $\Sigma$ and  $\tilde{\Sigma}$? 
\item Construct an example with three random variables exhibiting some correlation, such that the leading principal component fails to detect that correlation, but the leading factor analysis direction does recover it. ({\it Hint:} Construct data such that one variable is scaled differently from the rest, and use the previous result. )
\item Construct an example where the factor analysis method fails to reveal the true correlation structure of the data, but PCA is robust. ({\it Hint:} Think what happens when there is weak or absent correlation).
\item Consider the centered Factor Analysis model $X = AY + \epsilon$, with $X=(X_1,\dots, X_L)$ and $J < L$ uncorrelated factors $Y=(Y_1,\dots,Y_J)$, where $\E(\epsilon_i)=0$, $\text{var}(\epsilon_i) = \beta_i$. 
 Write down the joint data likelihood of the model when both $Y$ and $\epsilon$ are jointly Gaussian, and specify the loss that dictates how to obtain the parameters of the model ($A \in \R^{N \times L}$ and $\beta \in \R^L$) via MLE. 
\item Are the parameters of the model uniquely specified? Justify your answer.
\item If one supposes that $\beta_i = \beta_0$ for $i=1\dots L$, give an algorithm to estimate the MLE parameters in that case.
\end{enumerate}


\end{enumerate}

\end{document}
